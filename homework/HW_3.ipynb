{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HARSHITA MAHESH HIREMATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from itertools import tee\n",
    "from scipy.stats import wilcoxon\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(doc, lemmatized=False, remove_stopword=False, \n",
    "                   remove_punct = True, pos_tag = False):\n",
    "    \n",
    "    tokens =[]\n",
    "    \n",
    "    # add your code here\n",
    "    \n",
    "    # Load the SpaCy English model\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    \n",
    "    # Process the input document\n",
    "    doc = nlp(doc)\n",
    "        \n",
    "    for token in doc:\n",
    "        # Apply lemmatization if lemmatized is True\n",
    "        if lemmatized:\n",
    "            token_text = token.lemma_\n",
    "        else:\n",
    "            token_text = token.text\n",
    "        \n",
    "        # Remove stop words if remove_stopword is True\n",
    "        if remove_stopword and token.is_stop:\n",
    "            continue\n",
    "        \n",
    "        # Remove punctuation if remove_punct is True\n",
    "        if remove_punct and token.is_punct:\n",
    "            continue\n",
    "        \n",
    "        # Lowercase the token and remove empty tokens\n",
    "        cleaned_token = token_text.lower().strip()\n",
    "        if cleaned_token:\n",
    "            # Optionally retrieve the POS tag\n",
    "            if pos_tag:\n",
    "                tokens.append((cleaned_token, token.pos_))\n",
    "            else:\n",
    "                tokens.append(cleaned_token)            \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise(iterable):\n",
    "    a, b = tee(iterable)\n",
    "    next(b, None)\n",
    "    return zip(a, b)\n",
    "\n",
    "def compute_concreteness(doc):\n",
    "    \n",
    "    concreteness, articles, adpositions, quantifier = None, None, None, None\n",
    "\n",
    "    # add your code here\n",
    "\n",
    "    #Tokenize the document and retrieve POS tags\n",
    "    tokens = tokenize(doc, lemmatized=False, remove_stopword=False, remove_punct=False, pos_tag=True)\n",
    "    \n",
    "    #Generate bigrams\n",
    "    bigrams = list(pairwise(tokens))\n",
    "    \n",
    "    #Find unigrams with tags article or adposition\n",
    "    articles = [(token,pos_tag) for token, pos_tag in tokens if pos_tag in [\"DET\", \"ADP\"]]\n",
    "    \n",
    "    #Find adpositions\n",
    "    adpositions = [(token,pos_tag) for token, pos_tag in tokens if pos_tag == \"ADP\"]\n",
    "    \n",
    "    #Find bigrams where the first word is adjective and the second one is noun\n",
    "    adj_noun_bigrams = [[(token1,pos_tag1), (token2),pos_tag2] for (token1, pos_tag1), (token2, pos_tag2) in bigrams if pos_tag1 == \"ADJ\" and pos_tag2 == \"NOUN\"]\n",
    "    \n",
    "    #Compute concreteness score\n",
    "    non_punct_tokens = [(token,pos_tag) for token, pos_tag in tokens if pos_tag != \"PUNCT\"]\n",
    "    concreteness = ((len(articles) + len(adpositions) + 2 * len(adj_noun_bigrams)) / len(non_punct_tokens))\n",
    "    \n",
    "    return concreteness, articles, adpositions, [token for token in adj_noun_bigrams]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_quality(gen_tokens, ref_tokens):\n",
    "    result = None\n",
    "    \n",
    "    # add your code here\n",
    "\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    \n",
    "    for gen_answer, ref_answer in zip(gen_tokens, ref_tokens):\n",
    "        # Generate bigrams from the ChatGPT-generated and human answers\n",
    "        gen_bigrams = list(zip(gen_answer, gen_answer[1:]))\n",
    "        ref_bigrams = list(zip(ref_answer, ref_answer[1:]))\n",
    "\n",
    "        # Compute precision and recall for bigrams\n",
    "        common_bigrams = set(gen_bigrams) & set(ref_bigrams)\n",
    "        precision_bigrams = len(common_bigrams) / len(gen_bigrams) if len(gen_bigrams) > 0 else 0\n",
    "        recall_bigrams = len(common_bigrams) / len(ref_bigrams) if len(ref_bigrams) > 0 else 0\n",
    "\n",
    "        # Generate unigrams from the ChatGPT-generated and human answers\n",
    "        gen_unigrams = gen_answer\n",
    "        ref_unigrams = ref_answer\n",
    "\n",
    "        # Compute precision and recall for unigrams\n",
    "        common_unigrams = set(gen_unigrams) & set(ref_unigrams)\n",
    "        precision_unigrams = len(common_unigrams) / len(gen_unigrams) if len(gen_unigrams) > 0 else 0\n",
    "        recall_unigrams = len(common_unigrams) / len(ref_unigrams) if len(ref_unigrams) > 0 else 0\n",
    "\n",
    "        # Average precision and recall for both bigrams and unigrams\n",
    "        average_precision = (precision_bigrams + precision_unigrams) / 2\n",
    "        average_recall = (recall_bigrams + recall_unigrams) / 2\n",
    "\n",
    "        precision_scores.append(average_precision)\n",
    "        recall_scores.append(average_recall)\n",
    "        \n",
    "    precision = pd.DataFrame({'Precision': precision_scores})\n",
    "    recall = pd.DataFrame({'Recall': recall_scores})\n",
    "    result = pd.concat([precision,recall],axis=1)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tf_idf(tokenized_docs):\n",
    "    \n",
    "    smoothed_tf_idf = None\n",
    "    \n",
    "    # add your code here\n",
    "\n",
    "    # Convert tokenized documents back to text\n",
    "    text_docs = [' '.join(tokens) for tokens in tokenized_docs]\n",
    "\n",
    "    # Create a TfidfVectorizer to compute TF-IDF\n",
    "    tfidf_vectorizer = TfidfVectorizer(smooth_idf=True)\n",
    "\n",
    "    # Fit and transform the vectorizer on the text documents\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(text_docs)\n",
    "\n",
    "    # Normalize the TF-IDF matrix\n",
    "    tfidf_matrix = np.asarray(tfidf_matrix.todense())  # Convert to a dense matrix\n",
    "    row_sums = np.linalg.norm(tfidf_matrix, axis=1)  # Calculate L2 norm for each row\n",
    "    smoothed_tf_idf = tfidf_matrix / row_sums[:, np.newaxis]  # Normalize each row by dividing by L2 norm\n",
    "\n",
    "    return smoothed_tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_similarity(question_tokens, gen_tokens, ref_tokens):\n",
    "    \n",
    "    result = None\n",
    "    \n",
    "    # add your code here\n",
    "\n",
    "    # Combine all tokens into a single list\n",
    "    all_tokens = question_tokens + gen_tokens + ref_tokens\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "    # Calculate word embeddings for all tokens\n",
    "    token_embeddings = [nlp(' '.join(tokens)).vector for tokens in all_tokens]\n",
    "\n",
    "    # Split the embeddings into sub-lists\n",
    "    num_questions = len(question_tokens)\n",
    "    num_gen_answers = len(gen_tokens)\n",
    "\n",
    "    question_embeddings = token_embeddings[:num_questions]\n",
    "    gen_answer_embeddings = token_embeddings[num_questions:num_questions + num_gen_answers]\n",
    "    ref_answer_embeddings = token_embeddings[num_questions + num_gen_answers:]\n",
    "\n",
    "    # Calculate cosine similarities\n",
    "    question_gen_similarities = []\n",
    "    for question_embedding in question_embeddings:\n",
    "        similarities = [np.dot(question_embedding, gen_embedding) / (np.linalg.norm(question_embedding) * np.linalg.norm(gen_embedding))\n",
    "                        for gen_embedding in gen_answer_embeddings]\n",
    "        question_gen_similarities.append(np.mean(similarities))\n",
    "\n",
    "    question_ref_similarities = []\n",
    "    for question_embedding in question_embeddings:\n",
    "        similarities = [np.dot(question_embedding, ref_embedding) / (np.linalg.norm(question_embedding) * np.linalg.norm(ref_embedding))\n",
    "                        for ref_embedding in ref_answer_embeddings]\n",
    "        question_ref_similarities.append(np.mean(similarities))\n",
    "\n",
    "    gen_ref_similarities = [np.dot(gen_embedding, ref_embedding) / (np.linalg.norm(gen_embedding) * np.linalg.norm(ref_embedding))\n",
    "                           for gen_embedding, ref_embedding in zip(gen_answer_embeddings, ref_answer_embeddings)]\n",
    "\n",
    "    # Create a DataFrame with similarities\n",
    "    data = {\n",
    "        'Question/Generated Answer': question_gen_similarities,\n",
    "        'Question/Human Answer': question_ref_similarities,\n",
    "        'Generated Answer/Human Answer': gen_ref_similarities\n",
    "    }\n",
    "    result = pd.DataFrame(data)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import language_tool_python\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human Errors: [6, 78, 5, 5, 16]\n",
      "ChatGPT Errors: [1, 2, 1, 2, 5]\n"
     ]
    }
   ],
   "source": [
    "tool = language_tool_python.LanguageTool('en-US')\n",
    "data = pd.read_csv(\"qa.csv\")\n",
    "\n",
    "def count_grammar_errors(text):\n",
    "    matches = tool.check(text)\n",
    "    return len(matches)\n",
    "\n",
    "# Analyze human-generated answers and ChatGPT-generated answers\n",
    "human_answers = data[\"human_answer\"][:5]\n",
    "chatgpt_answers = data[\"chatgpt_answer\"][:5]\n",
    "\n",
    "human_errors = [count_grammar_errors(answer) for answer in human_answers]\n",
    "chatgpt_errors = [count_grammar_errors(answer) for answer in chatgpt_answers]\n",
    "\n",
    "# Compare grammatical errors\n",
    "print(\"Human Errors:\", human_errors)\n",
    "print(\"ChatGPT Errors:\", chatgpt_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human Modality: [(0, 0), (0, 0), (0, 0), (0, 0), (1, 0)]\n",
      "ChatGPT Modality: [(0, 0), (0, 0), (0, 0), (0, 0), (0, 0)]\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def analyze_modality(text):\n",
    "    doc = nlp(text)\n",
    "    strong_modality_words = [\"definitely\", \"certainly\", \"surely\"]\n",
    "    weak_modality_words = [\"maybe\", \"possibly\", \"probably\"]\n",
    "    strong_modality_count = sum(1 for token in doc if token.text in strong_modality_words)\n",
    "    weak_modality_count = sum(1 for token in doc if token.text in weak_modality_words)\n",
    "    return strong_modality_count, weak_modality_count\n",
    "\n",
    "# Analyze human-generated answers and ChatGPT-generated answers\n",
    "human_answers = data[\"human_answer\"][:5]\n",
    "chatgpt_answers = data[\"chatgpt_answer\"][:5]\n",
    "\n",
    "human_modality = [analyze_modality(answer) for answer in human_answers]\n",
    "chatgpt_modality = [analyze_modality(answer) for answer in chatgpt_answers]\n",
    "\n",
    "# Compare modality\n",
    "print(\"Human Modality:\", human_modality)\n",
    "print(\"ChatGPT Modality:\", chatgpt_modality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human Subjectivity: [0.45, 0.3566495066495067, 0.5429824561403509, 0.44000000000000006, 0.4841269841269841]\n",
      "ChatGPT Subjectivity: [0.6178062678062679, 0.3941176470588235, 0.5264485514485515, 0.3969065656565656, 0.453505291005291]\n"
     ]
    }
   ],
   "source": [
    "def analyze_subjectivity(text):\n",
    "    analysis = TextBlob(text)\n",
    "    sentiment = analysis.sentiment\n",
    "    return sentiment.subjectivity\n",
    "\n",
    "# Analyze human-generated answers and ChatGPT-generated answers\n",
    "human_answers = data[\"human_answer\"][:5]\n",
    "chatgpt_answers = data[\"chatgpt_answer\"][:5]\n",
    "\n",
    "human_subjectivity = [analyze_subjectivity(answer) for answer in human_answers]\n",
    "chatgpt_subjectivity = [analyze_subjectivity(answer) for answer in chatgpt_answers]\n",
    "\n",
    "# Compare subjectivity\n",
    "print(\"Human Subjectivity:\", human_subjectivity)\n",
    "print(\"ChatGPT Subjectivity:\", chatgpt_subjectivity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Question\n",
      "\n",
      "What happens if a parking ticket is lost / destroyed before the owner is aware of the ticket , and it goes unpaid ? I 've always been curious . Please explain like I'm five.\n",
      "\n",
      "1.lemmatized=False, remove_stopword=False, remove_punct = True,  pos_tag = False:\n",
      "     ['what', 'happens', 'if', 'a', 'parking', 'ticket', 'is', 'lost', 'destroyed', 'before', 'the', 'owner', 'is', 'aware', 'of', 'the', 'ticket', 'and', 'it', 'goes', 'unpaid', 'i', 've', 'always', 'been', 'curious', 'please', 'explain', 'like', 'i', \"'m\", 'five']\n",
      "\n",
      "2.lemmatized=False, remove_stopword=False, remove_punct = True,  pos_tag = True:\n",
      "     [('what', 'PRON'), ('happens', 'VERB'), ('if', 'SCONJ'), ('a', 'DET'), ('parking', 'NOUN'), ('ticket', 'NOUN'), ('is', 'AUX'), ('lost', 'VERB'), ('destroyed', 'VERB'), ('before', 'SCONJ'), ('the', 'DET'), ('owner', 'NOUN'), ('is', 'AUX'), ('aware', 'ADJ'), ('of', 'ADP'), ('the', 'DET'), ('ticket', 'NOUN'), ('and', 'CCONJ'), ('it', 'PRON'), ('goes', 'VERB'), ('unpaid', 'ADJ'), ('i', 'PRON'), ('ve', 'AUX'), ('always', 'ADV'), ('been', 'AUX'), ('curious', 'ADJ'), ('please', 'INTJ'), ('explain', 'VERB'), ('like', 'INTJ'), ('i', 'PRON'), (\"'m\", 'AUX'), ('five', 'NUM')]\n",
      "\n",
      "3.lemmatized=True, remove_stopword=True, remove_punct = True, pos_tag = False:\n",
      "     ['happen', 'parking', 'ticket', 'lose', 'destroy', 'owner', 'aware', 'ticket', 'go', 'unpaid', 've', 'curious', 'explain', 'like']\n",
      "\n",
      "4.lemmatized=True, remove_stopword=True, remove_punct = True, pos_tag = True:\n",
      "     [('happen', 'VERB'), ('parking', 'NOUN'), ('ticket', 'NOUN'), ('lose', 'VERB'), ('destroy', 'VERB'), ('owner', 'NOUN'), ('aware', 'ADJ'), ('ticket', 'NOUN'), ('go', 'VERB'), ('unpaid', 'ADJ'), ('ve', 'AUX'), ('curious', 'ADJ'), ('explain', 'VERB'), ('like', 'INTJ')]\n",
      "\n",
      "Second Question\n",
      "\n",
      "Question: why the waves do n't interfere ? first , I 'm sorry for my english . try to understand what I mean . there are lots of electromagnetic waves in the air such as radio waves . here is the question , why these waves interfere each other ? Explain like I'm five.  \n",
      "\n",
      "Concreteness: 0.3125 \n",
      "\n",
      "Articles:  [('the', 'DET'), ('for', 'ADP'), ('of', 'ADP'), ('in', 'ADP'), ('the', 'DET'), ('as', 'ADP'), ('the', 'DET'), ('these', 'DET'), ('each', 'DET')] \n",
      "\n",
      "Adpositions: [('for', 'ADP'), ('of', 'ADP'), ('in', 'ADP'), ('as', 'ADP')] \n",
      "\n",
      "(ADJ, NOUNS): [[('electromagnetic', 'ADJ'), 'waves', 'NOUN']]\n",
      "Third Question\n",
      "\n",
      "   Precision    Recall\n",
      "0   0.062570  0.156693\n",
      "1   0.104344  0.049235\n",
      "2   0.178880  0.075356\n",
      "3   0.067303  0.195354\n",
      "4   0.054936  0.138123\n",
      "Fourth Question\n",
      "\n",
      "1.lemmatized=False, remove_stopword=False, remove_punct = True:\n",
      "     Shape: 321400\n",
      "\n",
      "2.lemmatized=True, remove_stopword=True, remove_punct = True:\n",
      "     Shape: 249600\n",
      "\n",
      "Fifth Question\n",
      "\n",
      "   Question/Generated Answer  Question/Human Answer  \\\n",
      "0                   0.625870               0.660142   \n",
      "1                   0.696541               0.734288   \n",
      "2                   0.575833               0.562731   \n",
      "3                   0.483639               0.606338   \n",
      "4                   0.582579               0.582927   \n",
      "\n",
      "   Generated Answer/Human Answer  \n",
      "0                       0.747281  \n",
      "1                       0.851565  \n",
      "2                       0.899242  \n",
      "3                       0.877389  \n",
      "4                       0.619720  \n",
      "   Question/Generated Answer  Question/Human Answer  \\\n",
      "0                   0.532798               0.583491   \n",
      "1                   0.551384               0.619103   \n",
      "2                   0.508786               0.511152   \n",
      "3                   0.339504               0.512411   \n",
      "4                   0.512775               0.546176   \n",
      "\n",
      "   Generated Answer/Human Answer  \n",
      "0                       0.719596  \n",
      "1                       0.749856  \n",
      "2                       0.893438  \n",
      "3                       0.841156  \n",
      "4                       0.573498  \n",
      "   Question/Generated Answer  Question/Human Answer  \\\n",
      "0                   0.638525               0.667274   \n",
      "1                   0.690715               0.716915   \n",
      "2                   0.631341               0.612395   \n",
      "3                   0.569161               0.655608   \n",
      "4                   0.665364               0.654266   \n",
      "\n",
      "   Generated Answer/Human Answer  \n",
      "0                       0.778147  \n",
      "1                       0.816216  \n",
      "2                       0.907501  \n",
      "3                       0.879333  \n",
      "4                       0.721720  \n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":  \n",
    "    data = pd.read_csv(\"qa.csv\")\n",
    "    \n",
    "    print(\"First Question\\n\")\n",
    "    \n",
    "    print(data[\"question\"].iloc[0] + \"\\n\")\n",
    "\n",
    "    print(f\"1.lemmatized=False, remove_stopword=False, remove_punct = True,  pos_tag = False:\\n \\\n",
    "    {tokenize(data['question'].iloc[0], lemmatized=False, remove_stopword=False, remove_punct = True, pos_tag = False)}\\n\")\n",
    "\n",
    "    print(f\"2.lemmatized=False, remove_stopword=False, remove_punct = True,  pos_tag = True:\\n \\\n",
    "    {tokenize(data['question'].iloc[0], lemmatized=False, remove_stopword=False, remove_punct = True, pos_tag = True)}\\n\")\n",
    "\n",
    "    print(f\"3.lemmatized=True, remove_stopword=True, remove_punct = True, pos_tag = False:\\n \\\n",
    "    {tokenize(data['question'].iloc[0], lemmatized=True, remove_stopword=True, remove_punct = True, pos_tag = False)}\\n\")\n",
    "\n",
    "    print(f\"4.lemmatized=True, remove_stopword=True, remove_punct = True, pos_tag = True:\\n \\\n",
    "    {tokenize(data['question'].iloc[0], lemmatized=True, remove_stopword=True, remove_punct = True, pos_tag = True)}\\n\")\n",
    " \n",
    "    print(\"Second Question\\n\")\n",
    "    concreteness, articles, adpositions, quantifier = compute_concreteness(data[\"question\"].iloc[1])\n",
    "    print(f\"Question: {data['question'].iloc[1]} \\n\\nConcreteness: {concreteness :.4f} \\n\\nArticles:  {articles} \\n\\nAdpositions: {adpositions} \\n\\n(ADJ, NOUNS): {quantifier}\")\n",
    "    \n",
    "    print(\"Third Question\\n\")\n",
    "    gen_tokens = [tokenize(answer, lemmatized=False, remove_stopword=False, remove_punct=False, pos_tag=False) for answer in data['chatgpt_answer'][:5]]\n",
    "    ref_tokens = [tokenize(answer, lemmatized=False, remove_stopword=False, remove_punct=False, pos_tag=False) for answer in data['human_answer'][:5]]\n",
    "\n",
    "    result = answer_quality(gen_tokens, ref_tokens)\n",
    "    print(result.head())\n",
    "    \n",
    "    print(\"Fourth Question\\n\")\n",
    "    # Test tfidf generation using questions\n",
    "    question_tokens = [tokenize(answer, lemmatized=False, remove_stopword=False, remove_punct=True, pos_tag=False) for answer in data['question']]\n",
    "\n",
    "    # Configuration: lemmatized=False, remove_stopword=False, remove_punct = True, pos_tag = False\n",
    "    dtm = compute_tf_idf(question_tokens)\n",
    "    print(f\"1.lemmatized=False, remove_stopword=False, remove_punct = True:\\n \\\n",
    "    Shape: {dtm.size}\\n\")\n",
    "\n",
    "    # Configuration: lemmatized=True, remove_stopword=True, remove_punct = True, pos_tag = False\n",
    "    question_tokens = [tokenize(answer, lemmatized=True, remove_stopword=True, remove_punct=True, pos_tag=False) for answer in data['question']]\n",
    "    dtm = compute_tf_idf(question_tokens)\n",
    "    print(f\"2.lemmatized=True, remove_stopword=True, remove_punct = True:\\n \\\n",
    "    Shape: {dtm.size}\\n\")\n",
    "    \n",
    "    print(\"Fifth Question\\n\")\n",
    "    # Configuration: lemmatized=False, remove_stopword=False, remove_punct = True\n",
    "    question_tokens = [tokenize(answer, lemmatized=False, remove_stopword=False, remove_punct=True, pos_tag=False) for answer in data['question'][:5]]\n",
    "    gen_tokens = [tokenize(answer, lemmatized=False, remove_stopword=False, remove_punct=True, pos_tag=False) for answer in data['chatgpt_answer'][:5]]\n",
    "    ref_tokens = [tokenize(answer, lemmatized=False, remove_stopword=False, remove_punct=True, pos_tag=False) for answer in data['human_answer'][:5]]\n",
    "\n",
    "    result = assess_similarity(question_tokens, \n",
    "                               gen_tokens, \n",
    "                               ref_tokens)\n",
    "    print(result.head())\n",
    "\n",
    "    # You need to test other cases\n",
    "    question_tokens = [tokenize(answer, lemmatized=False, remove_stopword=False, remove_punct=False, pos_tag=False) for answer in data['question'][:5]]\n",
    "    gen_tokens = [tokenize(answer, lemmatized=False, remove_stopword=False, remove_punct=False, pos_tag=False) for answer in data['chatgpt_answer'][:5]]\n",
    "    ref_tokens = [tokenize(answer, lemmatized=False, remove_stopword=False, remove_punct=False, pos_tag=False) for answer in data['human_answer'][:5]]\n",
    "\n",
    "    result = assess_similarity(question_tokens, \n",
    "                               gen_tokens, \n",
    "                               ref_tokens)\n",
    "    print(result.head())\n",
    "\n",
    "    question_tokens = [tokenize(answer, lemmatized=True, remove_stopword=False, remove_punct=False, pos_tag=False) for answer in data['question'][:5]]\n",
    "    gen_tokens = [tokenize(answer, lemmatized=True, remove_stopword=False, remove_punct=False, pos_tag=False) for answer in data['chatgpt_answer'][:5]]\n",
    "    ref_tokens = [tokenize(answer, lemmatized=True, remove_stopword=False, remove_punct=False, pos_tag=False) for answer in data['human_answer'][:5]]\n",
    "\n",
    "    result = assess_similarity(question_tokens, \n",
    "                               gen_tokens, \n",
    "                               ref_tokens)\n",
    "    print(result.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
